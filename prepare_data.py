"""
–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö CSV —Ñ–∞–π–ª–æ–≤
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç, –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏ –ø—Ä–∏–º–µ–Ω—è–µ—Ç feature engineering
"""
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

import pandas as pd
from utils.data_loader import load_and_prepare_data
from features.feature_engineering import FraudFeatureEngineer


def prepare_data_for_inference(
    transactions_path: str = 'data/—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –≤ –ú–æ–±–∏–ª—å–Ω–æ–º –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –ë–∞–Ω–∫–∏–Ω–≥–µ.csv',
    behavioral_path: str = 'data/–ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫–ª–∏–µ–Ω—Ç–æ–≤.csv',
    output_path: str = None
) -> pd.DataFrame:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –ø—Ä–∏–º–µ–Ω—è–µ—Ç feature engineering –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç
    
    Args:
        transactions_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏
        behavioral_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏
        output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        DataFrame —Å –ø–æ–ª–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    """
    print("=" * 70)
    print("–ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –ú–û–®–ï–ù–ù–ò–ß–ï–°–¢–í–ê")
    print("=" * 70)
    
    # –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    print("\nüìä –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    print(f"  - –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏: {transactions_path}")
    print(f"  - –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {behavioral_path}")
    
    df = load_and_prepare_data(transactions_path, behavioral_path)
    
    print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")
    print(f"  - –õ–µ–≥–∏—Ç–∏–º–Ω—ã—Ö: {(df['is_fraud']==0).sum()}")
    print(f"  - –ú–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö: {(df['is_fraud']==1).sum()}")
    
    # –®–∞–≥ 2: Feature Engineering
    print("\nüîß –®–∞–≥ 2: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ feature engineering...")
    fe = FraudFeatureEngineer()
    df_features = fe.fit_transform(df)
    
    print(f"‚úì –°–æ–∑–¥–∞–Ω–æ {len(df_features.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
    # –®–∞–≥ 3: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if output_path:
        print(f"\nüíæ –®–∞–≥ 3: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞...")
        df_features.to_csv(output_path, index=False, encoding='utf-8')
        print(f"‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_path}")
    
    print("\n" + "=" * 70)
    print("‚úÖ –î–ê–ù–ù–´–ï –ì–û–¢–û–í–´ –ö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ")
    print("=" * 70)
    
    return df_features


def create_demo_samples(
    df: pd.DataFrame,
    n_clean: int = 5,
    n_fraud: int = 5,
    output_path: str = 'demo_batch_ready.csv'
) -> pd.DataFrame:
    """
    –°–æ–∑–¥–∞–µ—Ç –¥–µ–º–æ-–≤—ã–±–æ—Ä–∫—É –∏–∑ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    
    Args:
        df: DataFrame —Å –ø–æ–ª–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        n_clean: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–µ–≥–∏—Ç–∏–º–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
        n_fraud: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
        output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        
    Returns:
        DataFrame —Å –¥–µ–º–æ-–≤—ã–±–æ—Ä–∫–æ–π
    """
    print("\nüìã –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ-–≤—ã–±–æ—Ä–∫–∏...")
    
    # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
    clean = df[df['is_fraud'] == 0].sample(min(n_clean, len(df[df['is_fraud'] == 0])), random_state=42)
    fraud = df[df['is_fraud'] == 1].sample(min(n_fraud, len(df[df['is_fraud'] == 1])), random_state=42)
    
    demo_df = pd.concat([clean, fraud])
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    demo_df.to_csv(output_path, index=False, encoding='utf-8')
    
    print(f"‚úì –°–æ–∑–¥–∞–Ω–∞ –¥–µ–º–æ-–≤—ã–±–æ—Ä–∫–∞:")
    print(f"  - –õ–µ–≥–∏—Ç–∏–º–Ω—ã—Ö: {len(clean)}")
    print(f"  - –ú–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö: {len(fraud)}")
    print(f"  - –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_path}")
    
    return demo_df


def validate_data_format(df: pd.DataFrame) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ DataFrame —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    
    Args:
        df: DataFrame –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        
    Returns:
        True –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π, False –∏–Ω–∞—á–µ
    """
    required_columns = [
        'client_id', 'amount', 'transaction_datetime',
        'hour', 'day_of_week', 'is_weekend',
        'is_new_destination', 'client_avg_amount'
    ]
    
    missing = [col for col in required_columns if col not in df.columns]
    
    if missing:
        print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing}")
        return False
    
    print(f"‚úì –§–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π ({len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫)")
    return True


if __name__ == "__main__":
    import argparse
    import subprocess
    
    parser = argparse.ArgumentParser(description='–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞')
    parser.add_argument('--transactions', default='data/—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –≤ –ú–æ–±–∏–ª—å–Ω–æ–º –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –ë–∞–Ω–∫–∏–Ω–≥–µ.csv',
                        help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏')
    parser.add_argument('--behavioral', default='data/–ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫–ª–∏–µ–Ω—Ç–æ–≤.csv',
                        help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏')
    parser.add_argument('--output', default='processed_data.csv',
                        help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö')
    parser.add_argument('--demo', action='store_true',
                        help='–°–æ–∑–¥–∞—Ç—å –¥–µ–º–æ-–≤—ã–±–æ—Ä–∫—É')
    parser.add_argument('--demo-clean', type=int, default=5,
                        help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–µ–≥–∏—Ç–∏–º–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –≤ –¥–µ–º–æ')
    parser.add_argument('--demo-fraud', type=int, default=5,
                        help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –≤ –¥–µ–º–æ')
    parser.add_argument('--streamlit', action='store_true',
                        help='–ó–∞–ø—É—Å—Ç–∏—Ç—å Streamlit –ø–æ—Å–ª–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö')
    
    args = parser.parse_args()
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = prepare_data_for_inference(
        transactions_path=args.transactions,
        behavioral_path=args.behavioral,
        output_path=args.output
    )
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è
    validate_data_format(df)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ-–≤—ã–±–æ—Ä–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if args.demo:
        create_demo_samples(
            df,
            n_clean=args.demo_clean,
            n_fraud=args.demo_fraud,
            output_path='demo_batch_ready.csv'
        )
    
    print("\n‚úÖ –ì–æ—Ç–æ–≤–æ!")
    print(f"\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
    print(f"  1. –ü–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {args.output}")
    if args.demo:
        print(f"  2. –î–µ–º–æ-–≤—ã–±–æ—Ä–∫–∞: demo_batch_ready.csv")
    
    # –ó–∞–ø—É—Å–∫ Streamlit (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if args.streamlit:
        print("\nüöÄ –ó–∞–ø—É—Å–∫ Streamlit...")
        print("=" * 70)
        try:
            subprocess.run(['streamlit', 'run', 'app.py'], check=True)
        except KeyboardInterrupt:
            print("\n\n‚úì Streamlit –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        except Exception as e:
            print(f"\n‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ Streamlit: {e}")
            print("–ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤—Ä—É—á–Ω—É—é: streamlit run app.py")

