"""
Streamlit –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞
"""
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
import plotly.graph_objects as go
import plotly.express as px
import importlib
import sqlite3
from datetime import datetime

# Force reload inference module to get latest code
import inference
importlib.reload(inference)
from inference import FraudPredictor


# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="Fraud Detection System",
    page_icon="üîí",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS —Å—Ç–∏–ª–∏
st.markdown("""
<style>
    :root {
        --forte-magenta: #E6007E;      /* Forte */
        --forte-deep-purple: #5A2A83;  /* Forte Solo */
        --forte-noble-green: #2E7D32;  /* Forte Premier */
        --forte-dark-blue: #003366;   /* Forte Business */
        --forte-blue: #0066CC;        /* Forte Corporate */
    }
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: var(--forte-magenta);
        text-align: center;
        margin-bottom: 2rem;
    }
    .fraud-alert {
        background-color: var(--forte-dark-blue);
        color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #ff0000;
    }
    .clean-alert {
        background-color: var(--forte-noble-green);
        color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #00cc00;
    }
    .warning-alert {
        background-color: var(--forte-deep-purple);
        color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #ffcc00;
    }
    /* Streamlit button styling */
    .stButton > button {
        background-color: var(--forte-magenta) !important;
        color: white !important;
        border: none;
        border-radius: 0.25rem;
    }
    .stButton > button:hover {
        background-color: #c5006a !important;
    }
</style>
""", unsafe_allow_html=True)


def load_predictor():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
    model_path = '/usr/src/forte/models/fraud_detection_model.pkl'
    
    if not Path(model_path).exists():
        return None
    
    try:
        return FraudPredictor(model_path)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return None


def get_db_connection():
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î"""
    conn = sqlite3.connect('/usr/src/forte/history.db')
    conn.row_factory = sqlite3.Row
    return conn

def save_to_history(filename, status, details):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ –∏—Å—Ç–æ—Ä–∏—é"""
    try:
        conn = get_db_connection()
        conn.execute(
            'INSERT INTO upload_history (filename, status, details) VALUES (?, ?, ?)',
            (filename, status, details)
        )
        conn.commit()
        conn.close()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –∏—Å—Ç–æ—Ä–∏—é: {e}")

def get_history():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –∑–∞–≥—Ä—É–∑–æ–∫"""
    try:
        conn = get_db_connection()
        history = conn.execute('SELECT * FROM upload_history ORDER BY upload_time DESC').fetchall()
        conn.close()
        return history
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏: {e}")
        return []

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    st.markdown('<div class="main-header">Fraud Detection System</div>', unsafe_allow_html=True)
    st.markdown("---")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    predictor = load_predictor()
    
    if predictor is None:
        st.error("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–ø—É—Å—Ç–∏—Ç–µ train.py –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.")
        st.info("–ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ: `python train.py`")
        return
    

    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
    with st.sidebar:
        st.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        
        # –ü–æ—Ä–æ–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        threshold = st.slider(
            "–ü–æ—Ä–æ–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏",
            min_value=0.0,
            max_value=1.0,
            value=float(predictor.model.threshold),
            step=0.01,
            help="–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –≤—ã—à–µ —ç—Ç–æ–≥–æ –ø–æ—Ä–æ–≥–∞ –±—É–¥—É—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã –∫–∞–∫ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏–µ"
        )
        predictor.model.threshold = threshold
        
        st.markdown("---")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        st.subheader("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏")
        st.write(f"**–¢–∏–ø –º–æ–¥–µ–ª–∏:** CatBoost")
        st.write(f"**–ü—Ä–∏–∑–Ω–∞–∫–æ–≤:** {len(predictor.model.feature_cols)}")
        st.write(f"**–ü–æ—Ä–æ–≥:** {threshold:.3f}")
        
        st.markdown("---")
        
        # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—å—é
        st.subheader("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ")
        if st.button("–ü–µ—Ä–µ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å", help="–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –¥–æ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"):
            with st.spinner("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç."):
                import subprocess
                try:
                    # Run train.py in a subprocess
                    result = subprocess.run(
                        [sys.executable, "train.py"],
                        capture_output=True,
                        text=True,
                        cwd="/usr/src/forte"
                    )
                    if result.returncode == 0:
                        st.success("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞!")
                        st.cache_resource.clear() # Clear cache to reload model
                        # Reload predictor
                        predictor = load_predictor()
                    else:
                        st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏")
                        with st.expander("–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ—à–∏–±–∫–∏"):
                            st.code(result.stderr)
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞: {e}")

        st.markdown("---")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π —Ä–µ–∂–∏–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
        mode = st.radio(
            "–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã",
            ["–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏", "–ü–∞–∫–µ—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞", "–ò—Å—Ç–æ—Ä–∏—è –ø—Ä–æ–≤–µ—Ä–æ–∫", "–û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ñ–∞–π–ª—ã"],
            help="–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã"
        )

    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –≤ session_state
    if 'history' not in st.session_state:
        st.session_state.history = []

    # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
    if mode == "–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏":
        show_single_transaction_mode(predictor)
    elif mode == "–ü–∞–∫–µ—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞":
        show_batch_mode(predictor)
    elif mode == "–ò—Å—Ç–æ—Ä–∏—è –ø—Ä–æ–≤–µ—Ä–æ–∫":
        show_history_mode()
    elif mode == "–û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ñ–∞–π–ª—ã":
        show_merge_files_mode()

def show_history_mode():
    """–†–µ–∂–∏–º –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏—Å—Ç–æ—Ä–∏–∏"""
    st.header("–ò—Å—Ç–æ—Ä–∏—è –∑–∞–≥—Ä—É–∑–æ–∫ –∏ –ø—Ä–æ–≤–µ—Ä–æ–∫")
    
    history = get_history()
    
    if not history:
        st.info("–ò—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞")
        return
        
    # Convert to DataFrame for better display
    data = []
    for row in history:
        data.append({
            'ID': row['id'],
            '–§–∞–π–ª': row['filename'],
            '–í—Ä–µ–º—è': row['upload_time'],
            '–°—Ç–∞—Ç—É—Å': row['status'],
            '–î–µ—Ç–∞–ª–∏': row['details']
        })
    
    df = pd.DataFrame(data)
    st.dataframe(df, use_container_width=True)



def show_merge_files_mode():
    """–†–µ–∂–∏–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–≤—É—Ö CSV —Ñ–∞–π–ª–æ–≤ (—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ + –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã)"""
    st.header("–û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ñ–∞–π–ª—ã")
    st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–≤–∞ CSV‚Äë—Ñ–∞–π–ª–∞: —Ñ–∞–π–ª —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∏ —Ñ–∞–π–ª —Å –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏.")

    col1, col2 = st.columns(2)
    with col1:
        trans_file = st.file_uploader("–§–∞–π–ª —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π", type=["csv"], key="trans_file")
    with col2:
        beh_file = st.file_uploader("–§–∞–π–ª –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤", type=["csv"], key="beh_file")

    if trans_file is not None and beh_file is not None:
        # –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–æ–¥–∏—Ä–æ–≤–æ–∫ –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π
        def load_csv_smart(uploaded):
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
            encodings = ['cp1251', 'utf-8', 'latin1']
            separators = [';', ',']
            
            for enc in encodings:
                for sep in separators:
                    try:
                        uploaded.seek(0)
                        df = pd.read_csv(uploaded, encoding=enc, sep=sep)
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞, –≤–µ—Ä–æ—è—Ç–Ω–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –Ω–µ —Ç–æ—Ç
                        if df.shape[1] > 1:
                            return df
                    except Exception:
                        continue
            return None

        df_trans = load_csv_smart(trans_file)
        df_beh = load_csv_smart(beh_file)

        if df_trans is None or df_beh is None:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç (CSV) –∏ –∫–æ–¥–∏—Ä–æ–≤–∫—É.")
            return

        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ (–∏–∑ data_loader.py)
        trans_mapping = {
            '–£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–ª–∏–µ–Ω—Ç–∞': 'client_id',
            '–î–∞—Ç–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏': 'transaction_date',
            '–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏': 'transaction_datetime',
            '–°—É–º–º–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞': 'amount',
            '–£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏': 'transaction_id',
            '–ó–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–ª—É—á–∞—Ç–µ–ª—è/destination —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏': 'destination_id',
            '–†–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏(–ø–µ—Ä–µ–≤–æ–¥—ã), –≥–¥–µ 1 - –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è , 0 - —á–∏—Å—Ç–∞—è': 'is_fraud',
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
            'cst_dim_id': 'client_id',
            'transdate': 'transaction_date',
            'transdatetime': 'transaction_datetime',
            'docno': 'transaction_id',
            'direction': 'destination_id',
            'target': 'is_fraud'
        }
        
        # –î–ª—è –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –¢–û–õ–¨–ö–û –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
        # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏) –æ—Å—Ç–∞–≤–ª—è–µ–º –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –≤–∏–¥–µ,
        # —Ç–∞–∫ –∫–∞–∫ –º–æ–¥–µ–ª—å –æ–∂–∏–¥–∞–µ—Ç —Ä—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        beh_mapping = {
            '–£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–ª–∏–µ–Ω—Ç–∞': 'client_id',
            'UniqueCustomerID': 'client_id',
            'cst_dim_id': 'client_id',
            '–î–∞—Ç–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏': 'transaction_date',
            'date': 'transaction_date',
            'transdate': 'transaction_date',
        }

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª–µ–π –î–û –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è
        # –ò—â–µ–º cst_dim_id –∏ transdate –≤ –æ–±–æ–∏—Ö —Ñ–∞–π–ª–∞—Ö
        has_cst_dim_trans = 'cst_dim_id' in df_trans.columns
        has_cst_dim_beh = 'cst_dim_id' in df_beh.columns
        has_transdate_trans = 'transdate' in df_trans.columns
        has_transdate_beh = 'transdate' in df_beh.columns
        
        if not has_cst_dim_trans:
            st.error(f"–í —Ñ–∞–π–ª–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ 'cst_dim_id'. –ù–∞–π–¥–µ–Ω—ã: {list(df_trans.columns)}")
            return
        if not has_cst_dim_beh:
            st.error(f"–í —Ñ–∞–π–ª–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ 'cst_dim_id'. –ù–∞–π–¥–µ–Ω—ã: {list(df_beh.columns)}")
            return

        st.success(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df_trans)} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∏ {len(df_beh)} –∑–∞–ø–∏—Å–µ–π –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")

        # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –î–û –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
        # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏-–∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤–Ω—É—Ç—Ä–∏ –¥–∞–Ω–Ω—ã—Ö
        df_trans = df_trans[df_trans['cst_dim_id'] != 'cst_dim_id'].copy()
        df_beh = df_beh[df_beh['cst_dim_id'] != 'cst_dim_id'].copy()
        df_beh = df_beh[df_beh['cst_dim_id'] != 'UniqueCustomerID'].copy()
        
        # –û—á–∏—Å—Ç–∫–∞ cst_dim_id –æ—Ç –∫–∞–≤—ã—á–µ–∫
        df_trans['cst_dim_id'] = df_trans['cst_dim_id'].astype(str).str.replace("'", "", regex=False)
        df_beh['cst_dim_id'] = df_beh['cst_dim_id'].astype(str).str.replace("'", "", regex=False)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if has_transdate_trans:
            df_trans['transdate'] = df_trans['transdate'].astype(str).str.replace("'", "", regex=False)
            df_trans['transdate'] = pd.to_datetime(df_trans['transdate'], errors='coerce')
        
        if has_transdate_beh:
            df_beh['transdate'] = df_beh['transdate'].astype(str).str.replace("'", "", regex=False)
            df_beh['transdate'] = pd.to_datetime(df_beh['transdate'], errors='coerce')
        
        # –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –ü–û –û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ú –ü–û–õ–Ø–ú: cst_dim_id + transdate
        if has_transdate_trans and has_transdate_beh:
            # Join –ø–æ cst_dim_id + transdate (LEFT JOIN - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —Ñ–∞–π–ª–∞)
            merged = pd.merge(
                df_trans, 
                df_beh, 
                left_on=['cst_dim_id', 'transdate'],
                right_on=['cst_dim_id', 'transdate'],
                how='left',
                suffixes=('', '_beh')
            )
            st.info(f"‚úì –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ: cst_dim_id + transdate (LEFT JOIN)")
            
            # Save to history
            save_to_history(
                f"Merge: {trans_file.name} + {beh_file.name}", 
                "Success", 
                f"Merged {len(merged)} records"
            )
        else:
            # Fallback: join —Ç–æ–ª—å–∫–æ –ø–æ cst_dim_id (–µ—Å–ª–∏ –Ω–µ—Ç –¥–∞—Ç—ã)
            merged = pd.merge(
                df_trans, 
                df_beh, 
                on='cst_dim_id', 
                how='left',
                suffixes=('', '_beh')
            )
            st.warning("‚ö†Ô∏è –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø–æ cst_dim_id (transdate –Ω–µ –Ω–∞–π–¥–µ–Ω–∞)")
        
        # –¢–ï–ü–ï–†–¨ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –≤ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ
        merged.rename(columns=trans_mapping, inplace=True)
        merged.rename(columns=beh_mapping, inplace=True)
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∫–æ–ª–æ–Ω–æ–∫ –ø–æ—Å–ª–µ merge
        duplicate_cols = [col for col in merged.columns if col.endswith('_beh')]
        if duplicate_cols:
            merged = merged.drop(columns=duplicate_cols)
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã _x –∏ _y (–æ—Å—Ç–∞–≤–ª—è–µ–º _x, —É–¥–∞–ª—è–µ–º _y)
        cols_to_drop = []
        for col in merged.columns:
            if col.endswith('_y'):
                base_col = col[:-2]  # –£–¥–∞–ª—è–µ–º '_y'
                x_col = base_col + '_x'
                # –ï—Å–ª–∏ –µ—Å—Ç—å _x –≤–µ—Ä—Å–∏—è, –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –µ—ë –≤ –±–∞–∑–æ–≤–æ–µ –∏–º—è
                if x_col in merged.columns:
                    merged[base_col] = merged[x_col]
                    cols_to_drop.extend([x_col, col])
                else:
                    # –ï—Å–ª–∏ –Ω–µ—Ç _x, –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º _y –≤ –±–∞–∑–æ–≤–æ–µ –∏–º—è
                    merged[base_col] = merged[col]
                    cols_to_drop.append(col)
        
        if cols_to_drop:
            merged = merged.drop(columns=list(set(cols_to_drop)))
        
        # –§–ò–ù–ê–õ–¨–ù–û–ï –ü–ï–†–ï–ò–ú–ï–ù–û–í–ê–ù–ò–ï: —Ä—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è ‚Üí –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –∫–æ—Ä–æ—Ç–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        # –≠—Ç–æ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤ UI, –Ω–æ –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ä—É—Å—Å–∫–∏–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏
        final_rename_mapping = {
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏–π –û–° (os_ver) –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π –¥–æ transdate ‚Äî —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑–Ω—ã—Ö –û–°/–≤–µ—Ä—Å–∏–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –∫–ª–∏–µ–Ω—Ç': 'monthly_os_changes',
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Ç–µ–ª–µ—Ñ–æ–Ω–∞ (phone_model) –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π ‚Äî –Ω–∞—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–æ –∫–ª–∏–µ–Ω—Ç "–º–µ–Ω—è–ª —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ" –ø–æ –ª–æ–≥–∞–º': 'monthly_phone_model_changes',
            '–ú–æ–¥–µ–ª—å —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –∏–∑ —Å–∞–º–æ–π –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–µ—Å—Å–∏–∏ (–ø–æ –≤—Ä–µ–º–µ–Ω–∏) –ø–µ—Ä–µ–¥ transdate': 'last_phone_model_categorical',
            '–í–µ—Ä—Å–∏—è –û–° –∏–∑ —Å–∞–º–æ–π –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–µ—Å—Å–∏–∏ –ø–µ—Ä–µ–¥ transdate': 'last_os_categorical',
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª–æ–≥–∏–Ω-—Å–µ—Å—Å–∏–π (–º–∏–Ω—É—Ç–Ω—ã—Ö —Ç–∞–π–º-—Å–ª–æ—Ç–æ–≤) –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π –¥–æ transdate': 'logins_last_7_days',
            '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª–æ–≥–∏–Ω-—Å–µ—Å—Å–∏–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π –¥–æ transdate': 'logins_last_30_days',
            '–°—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ –ª–æ–≥–∏–Ω–æ–≤ –≤ –¥–µ–Ω—å –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π: logins_last_7_days / 7': 'login_frequency_7d',
            '–°—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ –ª–æ–≥–∏–Ω–æ–≤ –≤ –¥–µ–Ω—å –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π: logins_last_30_days / 30': 'login_frequency_30d',
            '–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã –ª–æ–≥–∏–Ω–æ–≤ –∑–∞ 7 –¥–Ω–µ–π –∫ —Å—Ä–µ–¥–Ω–µ–π —á–∞—Å—Ç–æ—Ç–µ –∑–∞ 30 –¥–Ω–µ–π:\n(freq7d?freq30d)/freq30d(freq_{7d} - freq_{30d}) / freq_{30d}(freq7d?freq30d)/freq30d ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —Å—Ç–∞–ª –∫–ª–∏–µ–Ω—Ç –∑–∞—Ö–æ–¥–∏—Ç—å —á–∞—â–µ –∏–ª–∏ —Ä–µ–∂–µ –Ω–µ–¥–∞–≤–Ω–æ': 'freq_change_7d_vs_mean',
            '–î–æ–ª—è –ª–æ–≥–∏–Ω–æ–≤ –∑–∞ 7 –¥–Ω–µ–π –æ—Ç –ª–æ–≥–∏–Ω–æ–≤ –∑–∞ 30 –¥–Ω–µ–π': 'logins_7d_over_30d_ratio',
            '–°—Ä–µ–¥–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö) –º–µ–∂–¥—É —Å–æ—Å–µ–¥–Ω–∏–º–∏ —Å–µ—Å—Å–∏—è–º–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π': 'avg_login_interval_30d',
            '–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏ –∑–∞ 30 –¥–Ω–µ–π (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö), –∏–∑–º–µ—Ä—è–µ—Ç —Ä–∞–∑–±—Ä–æ—Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤': 'std_login_interval_30d',
            '–î–∏—Å–ø–µ—Ä—Å–∏—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏ –∑–∞ 30 –¥–Ω–µ–π (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö¬≤), –µ—â—ë –æ–¥–Ω–∞ –º–µ—Ä–∞ —Ä–∞–∑–±—Ä–æ—Å–∞': 'var_login_interval_30d',
            '–î–∏—Å–ø–µ—Ä—Å–∏—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏ –∑–∞ 30 –¥–Ω–µ–π (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö?), –µ—â—ë –æ–¥–Ω–∞ –º–µ—Ä–∞ —Ä–∞–∑–±—Ä–æ—Å–∞': 'var_login_interval_30d',
            '–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏ –∑–∞ 7 –¥–Ω–µ–π, –≥–¥–µ –±–æ–ª–µ–µ —Å–≤–µ–∂–∏–µ —Å–µ—Å—Å–∏–∏ –∏–º–µ—é—Ç –±–æ–ª—å—à–∏–π –≤–µ—Å (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏—è 0.3)': 'ewm_login_interval_7d',
            '–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å "–≤–∑—Ä—ã–≤–Ω–æ—Å—Ç–∏" –ª–æ–≥–∏–Ω–æ–≤: (std‚àímean)/(std+mean)(std - mean)/(std + mean)(std‚àímean)/(std+mean) –¥–ª—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤': 'burstiness_login_interval',
            '–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å "–≤–∑—Ä—ã–≤–Ω–æ—Å—Ç–∏" –ª–æ–≥–∏–Ω–æ–≤: (std?mean)/(std+mean)(std - mean)/(std + mean)(std?mean)/(std+mean) –¥–ª—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤': 'burstiness_login_interval',
            'Fano-factor –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤: variance / mean': 'fano_factor_login_interval',
            'Z-—Å–∫–æ—Ä —Å—Ä–µ–¥–Ω–µ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–∞ 30 –¥–Ω–µ–π: –Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –Ω–µ–¥–∞–≤–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç —Ç–∏–ø–∏—á–Ω—ã—Ö, –≤ –µ–¥–∏–Ω–∏—Ü–∞—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è': 'zscore_avg_login_interval_7d'
        }
        merged.rename(columns=final_rename_mapping, inplace=True)
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∫–æ–ª–æ–Ω–æ–∫ (–æ—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ)
        merged = merged.loc[:, ~merged.columns.duplicated()]
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        required_columns = [
            'client_id', 'transaction_date', 'transaction_datetime', 'amount', 
            'transaction_id', 'destination_id', 'is_fraud',
            'monthly_os_changes', 'monthly_phone_model_changes', 
            'last_phone_model_categorical', 'last_os_categorical',
            'logins_last_7_days', 'logins_last_30_days', 
            'login_frequency_7d', 'login_frequency_30d',
            'freq_change_7d_vs_mean', 'logins_7d_over_30d_ratio',
            'avg_login_interval_30d', 'std_login_interval_30d', 
            'var_login_interval_30d', 'ewm_login_interval_7d',
            'burstiness_login_interval', 'fano_factor_login_interval', 
            'zscore_avg_login_interval_7d'
        ]
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ merged
        available_columns = [col for col in required_columns if col in merged.columns]
        merged = merged[available_columns]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

        st.success(f"‚úì –ü–æ–ª—É—á–µ–Ω–æ {len(merged)} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        behavioral_cols = [col for col in df_beh.columns if col not in ['client_id', 'transaction_date', 'transaction_date_key']]
        if behavioral_cols and behavioral_cols[0] in merged.columns:
            has_behavioral = merged[behavioral_cols[0]].notna().sum()
            st.info(f"‚úì –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π —Å –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏: {has_behavioral} ({has_behavioral/len(merged)*100:.1f}%)")
        st.dataframe(merged.head(1000))
        if len(merged) > 1000:
            st.warning(f"‚ö†Ô∏è –ü–æ–∫–∞–∑–∞–Ω—ã –ø–µ—Ä–≤—ã–µ 1000 —Å—Ç—Ä–æ–∫ –∏–∑ {len(merged)}. –°–∫–∞—á–∞–π—Ç–µ CSV –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö.")

        # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        csv = merged.to_csv(index=False, encoding='utf-8')
        st.download_button(
            label="üíæ –°–∫–∞—á–∞—Ç—å –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π CSV",
            data=csv,
            file_name="merged_data.csv",
            mime="text/csv",
        )
    else:
        st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–±–∞ —Ñ–∞–π–ª–∞, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç.")


def show_single_transaction_mode(predictor):
    """–†–µ–∂–∏–º –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ–¥–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏"""
    
    st.header("–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.subheader("–û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        
        amount = st.number_input(
            "–°—É–º–º–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ (‚Ç∏)",
            min_value=0.0,
            value=10000.0,
            step=100.0
        )
        
        destination_type = st.selectbox(
            "–¢–∏–ø –ø–æ–ª—É—á–∞—Ç–µ–ª—è",
            ["–ò–∑–≤–µ—Å—Ç–Ω—ã–π", "–ù–æ–≤—ã–π"]
        )
        is_new_destination = 1 if destination_type == "–ù–æ–≤—ã–π" else 0
        
        client_avg_amount = st.number_input(
            "–°—Ä–µ–¥–Ω—è—è —Å—É–º–º–∞ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –∫–ª–∏–µ–Ω—Ç–∞ (‚Ç∏)",
            min_value=0.0,
            value=5000.0,
            step=100.0
        )
    
    with col2:
        st.subheader("–í—Ä–µ–º—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏")
        
        hour = st.slider("–ß–∞—Å", 0, 23, 12)
        day_of_week = st.selectbox(
            "–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏",
            ["–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–í—Ç–æ—Ä–Ω–∏–∫", "–°—Ä–µ–¥–∞", "–ß–µ—Ç–≤–µ—Ä–≥", "–ü—è—Ç–Ω–∏—Ü–∞", "–°—É–±–±–æ—Ç–∞", "–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"]
        )
        day_of_week_num = ["–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–í—Ç–æ—Ä–Ω–∏–∫", "–°—Ä–µ–¥–∞", "–ß–µ—Ç–≤–µ—Ä–≥", "–ü—è—Ç–Ω–∏—Ü–∞", "–°—É–±–±–æ—Ç–∞", "–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"].index(day_of_week)
    
    with col3:
        st.subheader("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ")
        
        client_tx_count = st.number_input(
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—à–ª—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π",
            min_value=0,
            value=10,
            step=1
        )
        
        dest_tx_count = st.number_input(
            "–ü–µ—Ä–µ–≤–æ–¥–æ–≤ —ç—Ç–æ–º—É –ø–æ–ª—É—á–∞—Ç–µ–ª—é",
            min_value=0,
            value=0 if is_new_destination else 3,
            step=1
        )
    
    # –ö–Ω–æ–ø–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏
    st.markdown("---")
    
    if st.button("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é", type="primary", use_container_width=True):
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        transaction_data = {
            'amount': amount,
            'hour': hour,
            'day_of_week': day_of_week_num,
            'is_weekend': 1 if day_of_week_num >= 5 else 0,
            'is_night': 1 if hour >= 23 or hour <= 7 else 0,
            'is_morning': 1 if 6 <= hour <= 12 else 0,
            'is_evening': 1 if 18 <= hour <= 23 else 0,
            'log_amount': np.log1p(amount),
            'is_new_destination': is_new_destination,
            'client_tx_count': client_tx_count,
            'client_avg_amount': client_avg_amount,
            'client_median_amount': client_avg_amount,
            'amount_vs_median': amount / (client_avg_amount + 1),
            'amount_vs_avg': amount / (client_avg_amount + 1),
            'dest_tx_count': dest_tx_count,
            'is_round_amount': 1 if amount % 1000 == 0 else 0,
            'is_round_100': 1 if amount % 100 == 0 else 0,
        }
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        with st.spinner("–ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏..."):
            result = predictor.predict_single_transaction(transaction_data, explain=True)
            
            # Save to history
            st.session_state.history.insert(0, {
                'time': pd.Timestamp.now().strftime("%H:%M:%S"),
                'amount': amount,
                'prob': result['fraud_probability'],
                'rec': result['recommendation']
            })
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        st.markdown("---")
        st.header("–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞")
        
        # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
        fraud_prob = result['fraud_probability']
        
        # Gauge chart –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        fig = go.Figure(go.Indicator(
            mode="gauge+number",
            value=fraud_prob * 100,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞ (%)", 'font': {'size': 24}},
            gauge={
                'axis': {'range': [None, 100], 'tickwidth': 1, 'tickcolor': "darkblue"},
                'bar': {'color': "darkblue"},
                'bgcolor': "white",
                'borderwidth': 2,
                'bordercolor': "gray",
                'steps': [
                    {'range': [0, 30], 'color': '#ccffcc'},
                    {'range': [30, 80], 'color': '#ffffcc'},
                    {'range': [80, 100], 'color': '#ffcccc'}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': predictor.model.threshold * 100
                }
            }
        ))
        
        fig.update_layout(height=300)
        st.plotly_chart(fig, width="stretch")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å", f"{fraud_prob:.2%}")
        
        with col2:
            st.metric("–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è", "–ú–û–®–ï–ù–ù–ò–ß–ï–°–¢–í–û" if result['is_fraud'] else "–ß–ò–°–¢–ê–Ø")
        
        with col3:
            st.metric("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è", result['recommendation'])
        
        # –ê–ª–µ—Ä—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if result['recommendation'] == "–ë–õ–û–ö–ò–†–û–í–ê–¢–¨":
            st.markdown(f"""
            <div class="fraud-alert">
                <h3>–í–´–°–û–ö–ò–ô –†–ò–°–ö –ú–û–®–ï–ù–ù–ò–ß–ï–°–¢–í–ê</h3>
                <p>–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –∏ –ø—Ä–æ–≤–µ—Å—Ç–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É.</p>
            </div>
            """, unsafe_allow_html=True)
        elif result['recommendation'] == "–ü–†–û–í–ï–†–ò–¢–¨":
            st.markdown(f"""
            <div class="warning-alert">
                <h3>–°–†–ï–î–ù–ò–ô –†–ò–°–ö</h3>
                <p>–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏.</p>
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown(f"""
            <div class="clean-alert">
                <h3>–ù–ò–ó–ö–ò–ô –†–ò–°–ö</h3>
                <p>–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –≤—ã–≥–ª—è–¥–∏—Ç –ª–µ–≥–∏—Ç–∏–º–Ω–æ–π.</p>
            </div>
            """, unsafe_allow_html=True)
        
        # –¢–æ–ø —Ñ–∞–∫—Ç–æ—Ä–æ–≤
        if 'top_factors' in result and result['top_factors']:
            st.markdown("---")
            st.subheader("–ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–µ—à–µ–Ω–∏—è")
            
            factors_df = pd.DataFrame(result['top_factors'])
            
            # –ì—Ä–∞—Ñ–∏–∫ —Ñ–∞–∫—Ç–æ—Ä–æ–≤
            fig = px.bar(
                factors_df,
                x='contribution',
                y='feature',
                orientation='h',
                color='contribution',
                color_continuous_scale=['green', 'yellow', 'red'],
                labels={'contribution': '–í–∫–ª–∞–¥ –≤ —Ä–µ—à–µ–Ω–∏–µ', 'feature': '–ü—Ä–∏–∑–Ω–∞–∫'}
            )
            fig.update_layout(height=300)
            st.plotly_chart(fig, width="stretch")
            
            # –¢–∞–±–ª–∏—Ü–∞ —Ñ–∞–∫—Ç–æ—Ä–æ–≤
            st.dataframe(
                factors_df[['feature', 'value', 'impact']].rename(columns={
                    'feature': '–ü—Ä–∏–∑–Ω–∞–∫',
                    'value': '–ó–Ω–∞—á–µ–Ω–∏–µ',
                    'impact': '–í–ª–∏—è–Ω–∏–µ'
                }),
                use_container_width=True,
                hide_index=True
            )


def show_batch_mode(predictor):
    """–†–µ–∂–∏–º –ø–∞–∫–µ—Ç–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏"""
    
    st.header("–ü–∞–∫–µ—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")
    
    st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏ –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏")
    
    uploaded_file = st.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ CSV —Ñ–∞–π–ª",
        type=['csv'],
        help="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"
    )
    
    if uploaded_file is not None:
        try:
            # Smart CSV loading with separator and encoding detection
            def load_csv_smart(uploaded):
                encodings = ['utf-8', 'cp1251', 'latin1', 'windows-1251']
                separators = [',', ';', '\t', '|']
                
                for enc in encodings:
                    for sep in separators:
                        try:
                            uploaded.seek(0)
                            df = pd.read_csv(uploaded, encoding=enc, sep=sep, low_memory=False)
                            # Check if we got more than one column (successful parsing)
                            if df.shape[1] > 1:
                                return df
                        except Exception:
                            continue
                
                # If all attempts failed, try with default settings
                uploaded.seek(0)
                return pd.read_csv(uploaded, low_memory=False)
            
            df = load_csv_smart(uploaded_file)
            
            st.success(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")

            # –û—á–∏—Å—Ç–∫–∞ –æ—Ç –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (—Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ –ø—Ä–∏ —Å–∫–ª–µ–π–∫–µ —Ñ–∞–π–ª–æ–≤)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∫–æ–ª–æ–Ω–∫–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∫–æ–ª–æ–Ω–∫–∏
            rows_before = len(df)
            for col in df.columns:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏–ª–∏ object
                if df[col].dtype == 'object':
                    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ä–∞–≤–Ω–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∫–æ–ª–æ–Ω–∫–∏ (—Å —É—á–µ—Ç–æ–º –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤)
                    is_header = df[col].astype(str).str.strip() == col.strip()
                    if is_header.any():
                        df = df[~is_header]
            
            if len(df) < rows_before:
                st.warning(f"‚ö†Ô∏è –£–¥–∞–ª–µ–Ω–æ {rows_before - len(df)} —Å—Ç—Ä–æ–∫, —è–≤–ª—è—é—â–∏—Ö—Å—è –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏.")
            
            # Check if this is raw behavioral data (not processed features)
            # Look for Russian column names from behavioral patterns file
            behavioral_indicators = [
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏–π –û–°',
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Ç–µ–ª–µ—Ñ–æ–Ω–∞',
                '–ú–æ–¥–µ–ª—å —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –∏–∑ —Å–∞–º–æ–π –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–µ—Å—Å–∏–∏',
                '–í–µ—Ä—Å–∏—è –û–° –∏–∑ —Å–∞–º–æ–π –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–µ—Å—Å–∏–∏',
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª–æ–≥–∏–Ω-—Å–µ—Å—Å–∏–π'
            ]
            is_behavioral_data = any(
                any(indicator in str(col) for indicator in behavioral_indicators)
                for col in df.columns
            )
            
            # Check if this has required model features
            required_features = ['amount', 'hour', 'day_of_week']
            has_model_features = all(col in df.columns for col in required_features)
            
            if is_behavioral_data and not has_model_features:
                st.error("""
                ‚ùå **–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å—ã—Ä—ã–µ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ**
                
                –≠—Ç–æ—Ç —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫–ª–∏–µ–Ω—Ç–æ–≤, –Ω–æ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è—Ö.
                
                **–ß—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å:**
                1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ —Ä–µ–∂–∏–º "–û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ñ–∞–π–ª—ã"
                2. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –ò —Ñ–∞–π–ª –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
                3. –°–∫–∞—á–∞–π—Ç–µ –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Ñ–∞–π–ª
                4. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Ñ–∞–π–ª —Å—é–¥–∞ –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
                
                –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —É–∂–µ –≥–æ—Ç–æ–≤—ã–π —Ñ–∞–π–ª `demo_batch_ready.csv` –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
                """)
                return
            
            # –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä
            with st.expander("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö"):
                st.dataframe(df.head(10))
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ—Ä–æ–≥–∞
            threshold = st.slider(
                "–ü–æ—Ä–æ–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (Threshold)", 
                min_value=0.0, 
                max_value=1.0, 
                value=0.2,  # –ò–∑–º–µ–Ω–µ–Ω–æ —Å 0.5 –Ω–∞ 0.2 –¥–ª—è –ª—É—á—à–µ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¥–∞–Ω–Ω—ã–º
                step=0.01,
                help="–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –≤—ã—à–µ —ç—Ç–æ–≥–æ –ø–æ—Ä–æ–≥–∞ –±—É–¥—É—Ç —Å—á–∏—Ç–∞—Ç—å—Å—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏–º–∏. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Ç–∞–∫–∂–µ –∑–∞–≤–∏—Å—è—Ç –æ—Ç —ç—Ç–æ–≥–æ –ø–æ—Ä–æ–≥–∞."
            )
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö
            st.info(f"""
            **–ö–∞–∫ —Ä–∞–±–æ—Ç–∞—é—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
            - üî¥ **–ë–õ–û–ö–ò–†–û–í–ê–¢–¨**: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å ‚â• {threshold * 1.5:.2f} (–≤ 1.5 —Ä–∞–∑–∞ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞)
            - üü° **–ü–†–û–í–ï–†–ò–¢–¨**: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å ‚â• {threshold * 0.8:.2f} (–±–ª–∏–∑–∫–æ –∫ –ø–æ—Ä–æ–≥—É)
            - üü¢ **OK**: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å < {threshold * 0.8:.2f}
            
            –ò–∑–º–µ–Ω–∏—Ç–µ –ø–æ—Ä–æ–≥ –≤—ã—à–µ, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –±–æ–ª—å—à–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏.
            """)

            if st.button("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Å–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏", type="primary"):
                with st.spinner("–ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π..."):
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ session_state
                    st.session_state.batch_predictions = predictor.predict_batch(df)
                    
                    # Save to history
                    save_to_history(
                        uploaded_file.name, 
                        "Success", 
                        f"Processed {len(df)} transactions"
                    )
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ session_state
            if 'batch_predictions' in st.session_state:
                predictions = st.session_state.batch_predictions.copy()
                
                # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º is_fraud –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
                predictions['is_fraud'] = (predictions['fraud_probability'] >= threshold).astype(int)
                
                # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
                def get_recommendation(prob, threshold):
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ –∫–∞–∫ –±–∞–∑–æ–≤—ã–π
                    # –ë–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å - –µ—Å–ª–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞
                    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å - –µ—Å–ª–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ–∫–æ–ª–æ –ø–æ—Ä–æ–≥–∞
                    # OK - –µ—Å–ª–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞
                    if prob >= threshold * 1.5:  # –í 1.5 —Ä–∞–∑–∞ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞
                        return "–ë–õ–û–ö–ò–†–û–í–ê–¢–¨"
                    elif prob >= threshold * 0.8:  # –ë–ª–∏–∑–∫–æ –∫ –ø–æ—Ä–æ–≥—É (80% –æ—Ç –ø–æ—Ä–æ–≥–∞)
                        return "–ü–†–û–í–ï–†–ò–¢–¨"
                    else:
                        return "OK"
                
                predictions['recommendation'] = predictions['fraud_probability'].apply(
                    lambda x: get_recommendation(x, threshold)
                )
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                st.markdown("---")
                st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
                
                col1, col2, col3, col4 = st.columns(4)
                
                total = len(predictions)
                fraud_count = predictions['is_fraud'].sum()
                block_count = (predictions['recommendation'] == '–ë–õ–û–ö–ò–†–û–í–ê–¢–¨').sum()
                check_count = (predictions['recommendation'] == '–ü–†–û–í–ï–†–ò–¢–¨').sum()
                
                with col1:
                    st.metric("–í—Å–µ–≥–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π", total)
                
                with col2:
                    st.metric("–ú–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ", fraud_count, delta=f"{fraud_count/total*100:.1f}%")
                
                with col3:
                    st.metric("–ö –±–ª–æ–∫–∏—Ä–æ–≤–∫–µ", block_count)
                
                with col4:
                    st.metric("–ö –ø—Ä–æ–≤–µ—Ä–∫–µ", check_count)
                
                # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
                fig = px.histogram(
                    predictions,
                    x='fraud_probability',
                    nbins=50,
                    title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞",
                    labels={'fraud_probability': '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞'}
                )
                # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–Ω–∏—é –ø–æ—Ä–æ–≥–∞
                fig.add_vline(x=threshold, line_dash="dash", line_color="red", annotation_text=f"Threshold {threshold}")
                
                st.plotly_chart(fig, width="stretch")
                
                # –¢–∞–±–ª–∏—Ü–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
                st.subheader("–î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
                
                # –§–∏–ª—å—Ç—Ä
                filter_option = st.selectbox(
                    "–ü–æ–∫–∞–∑–∞—Ç—å",
                    ["–í—Å–µ", "–¢–æ–ª—å–∫–æ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ", "–ö –±–ª–æ–∫–∏—Ä–æ–≤–∫–µ", "–ö –ø—Ä–æ–≤–µ—Ä–∫–µ"]
                )
                
                if filter_option == "–¢–æ–ª—å–∫–æ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ":
                    display_df = predictions[predictions['is_fraud'] == 1]
                elif filter_option == "–ö –±–ª–æ–∫–∏—Ä–æ–≤–∫–µ":
                    display_df = predictions[predictions['recommendation'] == '–ë–õ–û–ö–ò–†–û–í–ê–¢–¨']
                elif filter_option == "–ö –ø—Ä–æ–≤–µ—Ä–∫–µ":
                    display_df = predictions[predictions['recommendation'] == '–ü–†–û–í–ï–†–ò–¢–¨']
                else:
                    display_df = predictions
                
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏, –Ω–æ –≤—ã–¥–µ–ª—è–µ–º –≤–∞–∂–Ω—ã–µ –≤ –Ω–∞—á–∞–ª–µ
                # –ü–µ—Ä–µ—É–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏: —Å–Ω–∞—á–∞–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, –ø–æ—Ç–æ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ
                result_cols = ['fraud_probability', 'is_fraud', 'recommendation']
                other_cols = [col for col in display_df.columns if col not in result_cols]
                ordered_cols = result_cols + other_cols
                
                st.dataframe(
                    display_df[ordered_cols],
                    width="stretch",
                    height=400
                )

                
                # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                csv = predictions.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (CSV)",
                    data=csv,
                    file_name="fraud_detection_results.csv",
                    mime="text/csv"
                )
        
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")


def show_history_mode():
    """–†–µ–∂–∏–º –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏—Å—Ç–æ—Ä–∏–∏"""
    st.header("–ò—Å—Ç–æ—Ä–∏—è –ø—Ä–æ–≤–µ—Ä–æ–∫")
    
    if not st.session_state.history:
        st.info("–ò—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π.")
        return
    
    history_df = pd.DataFrame(st.session_state.history)
    
    # –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü—ã
    def highlight_rec(val):
        color = 'green' if val == 'OK' else 'orange' if val == '–ü–†–û–í–ï–†–ò–¢–¨' else 'red'
        return f'color: {color}; font-weight: bold'
    
    st.dataframe(
        history_df.style.map(highlight_rec, subset=['rec']),
        width="stretch"
    )
    
    if st.button("–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é"):
        st.session_state.history = []
        st.rerun()


if __name__ == "__main__":
    main()
